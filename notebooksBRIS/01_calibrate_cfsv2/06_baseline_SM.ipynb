{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all of the python packages used in this workflow.\n",
    "import scipy\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "import os, sys\n",
    "from pylab import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "from datetime import date, datetime\n",
    "from datetime import timedelta  \n",
    "import json\n",
    "import itertools\n",
    "import os\n",
    "import requests\n",
    "\n",
    "\n",
    "######## USER INPUT HERE ONLY ##########\n",
    "\n",
    "# Use this for the 6-year SnowModel run info\n",
    "#start_years_list = [1988,1993,1998,2003,2008,2013]\n",
    "#end_years_list = [1994,1999,2004,2009,2014,2019]\n",
    "\n",
    "# Use this for the 2-year SnowModel run info\n",
    "# just do start years that have have a second year that overlaps with MODIS data\n",
    "# start_years_list = list(range(2000,2020))\n",
    "# print(start_years_list)\n",
    "\n",
    "########## USER ###########\n",
    "# Select modeling domain\n",
    "domain = 'BRIS'\n",
    "\n",
    "# SM location \n",
    "SMpath = '/nfs/attic/dfh/2020_NPRB/domain_'+domain+'/snowmodel2023_cfsv2/'\n",
    "# data location\n",
    "datapath = '/nfs/attic/dfh/2020_NPRB/data/'\n",
    "# SM forcing files \n",
    "SMdatapath = datapath+'SMinputs/'+domain+'/'\n",
    "# met forcing file name\n",
    "metFname = 'cfsv2_mm_'+domain+'_cal_wy2012-2018.dat'\n",
    "\n",
    "# location of SM forcing data\n",
    "dataPath = '/nfs/attic/dfh/2020_NPRB/data/SMinputs/'+domain+'/'\n",
    "\n",
    "#path to CSO domains\n",
    "domains_resp = requests.get(\"https://raw.githubusercontent.com/NPRB/02_preprocess_python/main/NPRB_domains.json\")\n",
    "domains = domains_resp.json()\n",
    "\n",
    "#start calibration date    \n",
    "st_dt = '2011-10-01'\n",
    "#end calibration date\n",
    "ed_dt = '2018-09-30'\n",
    "\n",
    "#Snotel bounding box\n",
    "Bbox = domains[domain]['Bbox']\n",
    "\n",
    "# Snotel projection\n",
    "stn_proj = domains[domain]['stn_proj']\n",
    "# model projection\n",
    "mod_proj = domains[domain]['mod_proj']\n",
    "\n",
    "# Paths\n",
    "parFile = SMpath+'snowmodel.par'\n",
    "incFile = SMpath+'code/snowmodel.inc'\n",
    "compileFile = SMpath+'code/compile_snowmodel.script'\n",
    "ctlFile = SMpath+'ctl_files/wo_assim/swed.ctl'\n",
    "micrometFile = SMpath+'code/micromet_code.f'\n",
    "sweFile = SMpath+'outputs/wo_assim/swed.gdat'\n",
    "codepath = SMpath+'code'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Function to edit text files docs\n",
    "\n",
    "\n",
    "#function to edit SnowModel Files other than .par\n",
    "def replace_line(file_name, line_num, text):\n",
    "    lines = open(file_name, 'r').readlines()\n",
    "    lines[line_num] = text\n",
    "    out = open(file_name, 'w')\n",
    "    out.writelines(lines)\n",
    "    out.close()\n",
    "\n",
    "\n",
    "\n",
    "#Edit the par file to set parameters with new values\n",
    "def edit_par(par_dict,parameter,new_value,parFile):\n",
    "    lines = open(parFile, 'r').readlines()\n",
    "    if par_dict[parameter][2] == 14 or par_dict[parameter][2] == 17 \\\n",
    "    or par_dict[parameter][2] == 18 or par_dict[parameter][2] == 19 \\\n",
    "    or par_dict[parameter][2] == 93 or par_dict[parameter][2] == 95 \\\n",
    "    or par_dict[parameter][2] == 97 or par_dict[parameter][2] == 100 \\\n",
    "    or par_dict[parameter][2] == 102 or par_dict[parameter][2] == 104 \\\n",
    "    or par_dict[parameter][2] == 107 or par_dict[parameter][2] == 108 \\\n",
    "    or par_dict[parameter][2] == 147 or par_dict[parameter][2] == 148 \\\n",
    "    or par_dict[parameter][2] == 149:\n",
    "        text = str(new_value)+'\\n'\n",
    "    else:\n",
    "        text = str(new_value)+'\\t\\t\\t!'+par_dict[parameter][1]\n",
    "    lines[par_dict[parameter][2]] = text\n",
    "    out = open(parFile, 'w')\n",
    "    out.writelines(lines)\n",
    "    out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import baseline .par parameters\n",
    "with open('/nfs/attic/dfh/2020_NPRB/data/json/par_base.json') as f:\n",
    "    base = json.load(f)\n",
    "\n",
    "# set .par to have default parameters\n",
    "for key in base:\n",
    "    edit_par(base,key,base[key][0],parFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'949'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "domains[domain]['ncols']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#edit snowmodel.par to run SM as a line \n",
    "# spatial inputs\n",
    "edit_par(base,'nx',domains[domain]['ncols'],parFile)\n",
    "edit_par(base,'ny',domains[domain]['nrows'],parFile)\n",
    "edit_par(base,'xmn',domains[domain]['xll'],parFile)\n",
    "edit_par(base,'ymn',domains[domain]['yll'],parFile)\n",
    "edit_par(base,'deltax',domains[domain]['cellsize'],parFile)\n",
    "edit_par(base,'deltay',domains[domain]['cellsize'],parFile)\n",
    "# temporal inputs\n",
    "edit_par(base,'dt',21600,parFile) #seconds per model time step\n",
    "edit_par(base,'iyear_init',datetime.strptime(st_dt,'%Y-%m-%d').year,parFile)\n",
    "edit_par(base,'imonth_init',datetime.strptime(st_dt,'%Y-%m-%d').month,parFile)\n",
    "edit_par(base,'iday_init',datetime.strptime(st_dt,'%Y-%m-%d').day,parFile)\n",
    "edit_par(base,'xhour_init',datetime.strptime(st_dt,'%Y-%m-%d').hour,parFile)\n",
    "max_iter = (datetime.strptime(ed_dt,'%Y-%m-%d')-datetime.strptime(st_dt,'%Y-%m-%d')).days*4+4\n",
    "edit_par(base,'max_iter',max_iter,parFile)\n",
    "# paths \n",
    "#edit_par(base,'met_input_fname','../../data/SMinputs/'+domain+'/'+metFname,parFile)\n",
    "edit_par(base,'met_input_fname','../../data/SMinputs/'+domain+'/'+metFname,parFile)\n",
    "edit_par(base,'ascii_topoveg',1,parFile)\n",
    "edit_par(base,'topo_ascii_fname','../../data/SMinputs/'+domain+'/'+domain+'_dem.asc',parFile)\n",
    "edit_par(base,'veg_ascii_fname','../../data/SMinputs/'+domain+'/'+domain+'_veg.asc',parFile)\n",
    "edit_par(base,'lat_file_path','../../data/SMinputs/'+domain+'/'+domain+'_grid_lat.asc',parFile)\n",
    "edit_par(base,'lon_file_path','../../data/SMinputs/'+domain+'/'+domain+'_grid_lon.asc',parFile)\n",
    "edit_par(base,'output_path_wo_assim','outputs/wo_assim/',parFile)\n",
    "#other flags to calibrate SM as line\n",
    "edit_par(base,'xlat',round(domains[domain]['Bbox']['latmin']+(domains[domain]['Bbox']['latmax']-domains[domain]['Bbox']['latmin'])/2,2),parFile)\n",
    "edit_par(base,'run_snowtran',0,parFile)\n",
    "edit_par(base,'barnes_lg_domain',1,parFile)\n",
    "edit_par(base,'lat_solar_flag',1,parFile)\n",
    "edit_par(base,'snowmodel_line_flag',0,parFile)\n",
    "edit_par(base,'print_inc',4,parFile)\n",
    "edit_par(base,'print_var_01','y',parFile)#tair\n",
    "edit_par(base,'print_var_09','y',parFile)#prec\n",
    "edit_par(base,'print_var_10','n',parFile)#rain\n",
    "edit_par(base,'print_var_11','n',parFile)#sprec\n",
    "edit_par(base,'print_var_12','y',parFile)#swemelt\n",
    "edit_par(base,'print_var_14','y',parFile)#runoff\n",
    "edit_par(base,'print_var_18','y',parFile)#swed\n",
    "edit_par(base,'print_var_13','y',parFile)#subl\n",
    "edit_par(base,'cf_precip_flag',0,parFile)\n",
    "edit_par(base,'UTC_flag',1,parFile)\n",
    "edit_par(base,'n_stns_used',4,parFile)\n",
    "edit_par(base,'check_met_data',0,parFile)\n",
    "edit_par(base,'multilayer_snowpack',1,parFile)\n",
    "edit_par(base,'max_layers',6,parFile)\n",
    "edit_par(base,'lapse_rate_user_flag',0,parFile)\n",
    "edit_par(base,'cf_precip_scalar',1,parFile) \n",
    "\n",
    "##edit snowmodel.inc\n",
    "replace_line(incFile, 12, '      parameter (nx_max='+str(int(domains[domain]['ncols'])+1)+',ny_max='+str(int(domains[domain]['nrows'])+1)+')\\n')\n",
    "replace_line(incFile, 18, '      parameter (max_time_steps='+str(max_iter+1)+')\\n') \n",
    "replace_line(incFile, 41, '      parameter (nz_max=21)\\n') \n",
    "#replace_line(incFile, 12, '      parameter (nx_max=1383,ny_max=2477)\\n')#full domain\n",
    "\n",
    "\n",
    "###edit compile_snowmodel.script\n",
    "##replace_line(compileFile, 16, '#pgf77 -O3 -mcmodel=medium -I$path -o ../snowmodel $path$filename1 $path$filename2 $path$filename3 $path$filename4 $path$filename5 $path$filename6 $path$filename7 $path$filename8 $path$filename9 $path$filename10\\n')\n",
    "#replace_line(compileFile, 20, 'gfortran -O3 -mcmodel=medium -I$path -o ../snowmodel $path$filename1 $path$filename2 $path$filename3 $path$filename4 $path$filename5 $path$filename6 $path$filename7 $path$filename8 $path$filename9 $path$filename10\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to edit time-related parameters in .par for 2 year simulations\n",
    "def change_dates(styr):\n",
    "    st = pd.to_datetime(str(styr)+'-10-01',format=\"%Y-%m-%d\")\n",
    "    ed = pd.to_datetime(str(styr+2)+'-09-30',format=\"%Y-%m-%d\")\n",
    "    edit_par(base,'iyear_init',str(st.year),parFile)\n",
    "    edit_par(base,'imonth_init',str(st.month),parFile)\n",
    "    edit_par(base,'iday_init',str(st.day),parFile)\n",
    "    edit_par(base,'xhour_init',str(st.hour),parFile)\n",
    "    edit_par(base,'max_iter',str((ed-st).days*4+4),parFile)\n",
    "    edit_par(base,'met_input_fname','../../data/SMinputs/'+domain+'/mm_'+domain+'_'+str(st.year)+'-'+str(ed.year)+'.dat',parFile)\n",
    "    edit_par(base,'output_path_wo_assim','outputs/wo_assim_'+str(st.year)+'-'+str(ed.year)+'/',parFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_snowmodel():\n",
    "    # Move to code\n",
    "    %cd $codepath\n",
    "    # Run compile script \n",
    "    ! ./compile_snowmodel.script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_snowmodel():\n",
    "    %cd $SMpath\n",
    "    ! nohup ./snowmodel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/nfs/attic/dfh/2020_NPRB/domain_BEAU/test/code\n",
      "/nfs/attic/dfh/2020_NPRB/domain_BEAU/test\n",
      "nohup: ignoring input and appending output to ‘nohup.out’\n"
     ]
    }
   ],
   "source": [
    "styr = start_years_list[-1]\n",
    "change_dates(styr)\n",
    "compile_snowmodel()\n",
    "run_snowmodel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2001\n",
      "editing .par file\n",
      "compiling snowmodel\n",
      "running rnowmodel\n",
      "2002\n",
      "editing .par file\n",
      "compiling snowmodel\n",
      "running rnowmodel\n",
      "2003\n",
      "editing .par file\n",
      "compiling snowmodel\n",
      "running rnowmodel\n",
      "2004\n",
      "editing .par file\n",
      "compiling snowmodel\n",
      "running rnowmodel\n",
      "2005\n",
      "editing .par file\n",
      "compiling snowmodel\n",
      "running rnowmodel\n",
      "2006\n",
      "editing .par file\n",
      "compiling snowmodel\n",
      "running rnowmodel\n",
      "2007\n",
      "editing .par file\n",
      "compiling snowmodel\n",
      "running rnowmodel\n",
      "2008\n",
      "editing .par file\n",
      "compiling snowmodel\n",
      "running rnowmodel\n",
      "2009\n",
      "editing .par file\n",
      "compiling snowmodel\n",
      "running rnowmodel\n",
      "2010\n",
      "editing .par file\n",
      "compiling snowmodel\n",
      "running rnowmodel\n",
      "2011\n",
      "editing .par file\n",
      "compiling snowmodel\n",
      "running rnowmodel\n",
      "2012\n",
      "editing .par file\n",
      "compiling snowmodel\n",
      "running rnowmodel\n",
      "2013\n",
      "editing .par file\n",
      "compiling snowmodel\n",
      "running rnowmodel\n",
      "2014\n",
      "editing .par file\n",
      "compiling snowmodel\n",
      "running rnowmodel\n",
      "2015\n",
      "editing .par file\n",
      "compiling snowmodel\n",
      "running rnowmodel\n",
      "2016\n",
      "editing .par file\n",
      "compiling snowmodel\n",
      "running rnowmodel\n",
      "2017\n",
      "editing .par file\n",
      "compiling snowmodel\n",
      "running rnowmodel\n",
      "2018\n",
      "editing .par file\n",
      "compiling snowmodel\n",
      "running rnowmodel\n"
     ]
    }
   ],
   "source": [
    "for styr in start_years_list:\n",
    "    print(styr)\n",
    "    print('editing .par file')\n",
    "    change_dates(styr)\n",
    "    \n",
    "    # Compile snowmodel\n",
    "    print('compiling snowmodel')\n",
    "    compile_snowmodel()\n",
    "    \n",
    "    # run snowmodel\n",
    "    print('running rnowmodel')\n",
    "    run_snowmodel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nprb]",
   "language": "python",
   "name": "conda-env-nprb-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
